{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 1: Automated Scenario Modeling System\n",
    "\n",
    "**Objective:** Build a Monte Carlo simulation engine that projects operational KPIs under multiple scenarios (optimistic, baseline, pessimistic, worst-case) and uses Claude AI to interpret the results.\n",
    "\n",
    "**What this notebook demonstrates:**\n",
    "1. Synthetic data generation for 10 operational metrics across 3 manufacturing facilities\n",
    "2. Statistical processing pipeline (trends, anomaly detection, correlations)\n",
    "3. Monte Carlo scenario projections with configurable parameters\n",
    "4. Interactive visualizations of projection uncertainty bands\n",
    "5. AI-powered interpretation of scenario outcomes via Claude API\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')  # project root\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from shared.data_generation.generate import generate_operational_metrics\n",
    "from shared.utils.processing import run_full_processing\n",
    "from shared.utils.plotting import apply_portfolio_style, save_figure, COLORS, SCENARIO_COLORS\n",
    "from shared.config.loader import SETTINGS\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Operational Data\n",
    "\n",
    "We generate 24 months of data for 3 manufacturing plants, each tracking 10 KPIs.\n",
    "The data includes realistic trends, seasonality, facility-level differences, and occasional anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = generate_operational_metrics()\n",
    "\n",
    "print(f'Dataset shape: {raw_df.shape}')\n",
    "print(f'Date range: {raw_df[\"date\"].min().date()} to {raw_df[\"date\"].max().date()}')\n",
    "print(f'Facilities: {raw_df[\"facility\"].unique().tolist()}')\n",
    "print(f'Metrics: {raw_df[\"metric\"].nunique()}')\n",
    "print()\n",
    "raw_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data for other deliverables\n",
    "from shared.data_generation.generate import save_data\n",
    "save_data(raw_df, '../data')\n",
    "save_data(raw_df, '../../02_insight_extraction/data')\n",
    "save_data(raw_df, '../../03_strategic_dashboard/data')\n",
    "print('Data saved to all deliverable folders.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Before modeling, let's understand the data — distributions, trends, and facility differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview: metric distributions by facility\n",
    "fig = px.box(\n",
    "    raw_df, x='metric', y='value', color='facility',\n",
    "    color_discrete_map=COLORS,\n",
    ")\n",
    "fig = apply_portfolio_style(fig, 'Metric Distributions by Facility')\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(height=500)\n",
    "save_figure(fig, '../outputs/metric_distributions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series: select key metrics\n",
    "key_metrics = ['production_output', 'quality_rate', 'defect_rate_ppm', 'on_time_delivery_pct']\n",
    "\n",
    "fig = px.line(\n",
    "    raw_df[raw_df['metric'].isin(key_metrics)],\n",
    "    x='date', y='value', color='facility', facet_row='metric',\n",
    "    color_discrete_map=COLORS,\n",
    "    height=800,\n",
    ")\n",
    "fig = apply_portfolio_style(fig, 'Key Metric Trends (24 Months)')\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[-1].replace('_', ' ').title()))\n",
    "save_figure(fig, '../outputs/key_metric_trends')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing Pipeline\n",
    "\n",
    "Run statistical processing: summary stats, month-over-month trends, anomaly detection, and cross-metric correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = run_full_processing(raw_df)\n",
    "\n",
    "for name, df in processed.items():\n",
    "    print(f'{name}: {df.shape}')\n",
    "\n",
    "print(f'\\nAnomalies detected: {len(processed[\"anomalies\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats\n",
    "processed['summary'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomalies\n",
    "anom = processed['anomalies']\n",
    "if len(anom) > 0:\n",
    "    fig = px.scatter(\n",
    "        anom, x='date', y='z_score', color='facility', symbol='metric',\n",
    "        size=anom['z_score'].abs(),\n",
    "        color_discrete_map=COLORS,\n",
    "    )\n",
    "    fig.add_hline(y=2.0, line_dash='dash', line_color='red', opacity=0.5)\n",
    "    fig.add_hline(y=-2.0, line_dash='dash', line_color='red', opacity=0.5)\n",
    "    fig = apply_portfolio_style(fig, 'Detected Anomalies (|z-score| > 2.0)')\n",
    "    fig.update_layout(height=450)\n",
    "    save_figure(fig, '../outputs/anomalies')\n",
    "    fig.show()\n",
    "else:\n",
    "    print('No anomalies detected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monte Carlo Scenario Modeling\n",
    "\n",
    "We project each metric forward 12 months under 4 scenarios:\n",
    "- **Optimistic** (+15% trend amplification)\n",
    "- **Baseline** (current trajectory)\n",
    "- **Pessimistic** (-15% trend reversal)\n",
    "- **Worst Case** (-30% trend reversal)\n",
    "\n",
    "Each scenario runs 200 Monte Carlo simulations to capture uncertainty bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import importlib, types\n\n# Import from digit-prefixed folder using importlib\ndef import_from(module_path, module_name):\n    \"\"\"Import a module from a path that may start with digits.\"\"\"\n    import importlib.util\n    spec = importlib.util.spec_from_file_location(module_name, module_path)\n    mod = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(mod)\n    return mod\n\nmodeler = import_from('../../01_scenario_modeling/src/modeler.py', 'modeler')\n\nscenarios = modeler.run_all_scenarios(raw_df)\nflat_df = modeler.scenarios_to_flat_df(scenarios)\nendpoint_df = modeler.scenarios_endpoint_summary(scenarios)\n\nprint(f'Scenario projections generated: {len(flat_df)} data points')\nprint(f'Endpoint summary: {len(endpoint_df)} rows')\nendpoint_df.head(10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scenario fan charts for a key metric\n",
    "def plot_scenario_fan(scenarios_dict, facility, metric, title=None):\n",
    "    \"\"\"Plot scenario projection fan chart with uncertainty bands.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for scenario_name, proj_df in scenarios_dict[facility][metric].items():\n",
    "        color = SCENARIO_COLORS.get(scenario_name, '#888')\n",
    "        \n",
    "        # Uncertainty band (p10-p90)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=pd.concat([proj_df['month'], proj_df['month'][::-1]]),\n",
    "            y=pd.concat([proj_df['p90'], proj_df['p10'][::-1]]),\n",
    "            fill='toself', fillcolor=color, opacity=0.15,\n",
    "            line=dict(width=0), showlegend=False, name=f'{scenario_name} band',\n",
    "        ))\n",
    "        # Median line\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=proj_df['month'], y=proj_df['median'],\n",
    "            mode='lines', name=scenario_name.replace('_', ' ').title(),\n",
    "            line=dict(color=color, width=2.5),\n",
    "        ))\n",
    "    \n",
    "    title = title or f'{metric.replace(\"_\", \" \").title()} — {facility} — 12 Month Projection'\n",
    "    fig = apply_portfolio_style(fig, title)\n",
    "    fig.update_xaxes(title_text='Months Ahead')\n",
    "    fig.update_yaxes(title_text='Projected Value')\n",
    "    fig.update_layout(height=450)\n",
    "    return fig\n",
    "\n",
    "fig = plot_scenario_fan(scenarios, 'Plant Alpha', 'production_output')\n",
    "save_figure(fig, '../outputs/scenario_fan_production')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scenario_fan(scenarios, 'Plant Beta', 'quality_rate')\n",
    "save_figure(fig, '../outputs/scenario_fan_quality')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scenario_fan(scenarios, 'Plant Gamma', 'defect_rate_ppm')\n",
    "save_figure(fig, '../outputs/scenario_fan_defects')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty range comparison across all metrics\n",
    "uncertainty = endpoint_df.groupby(['metric', 'scenario'])['uncertainty_range'].mean().reset_index()\n",
    "\n",
    "fig = px.bar(\n",
    "    uncertainty, x='metric', y='uncertainty_range', color='scenario',\n",
    "    barmode='group', color_discrete_map=SCENARIO_COLORS,\n",
    ")\n",
    "fig = apply_portfolio_style(fig, 'Projection Uncertainty by Metric & Scenario')\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(height=500)\n",
    "save_figure(fig, '../outputs/uncertainty_comparison')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facility resilience: how much does each facility's median drop under worst case vs baseline?\n",
    "pivot = endpoint_df.pivot_table(\n",
    "    index=['facility', 'metric'], columns='scenario', values='projected_median'\n",
    ").reset_index()\n",
    "pivot['resilience_pct'] = ((pivot['worst_case'] - pivot['baseline']) / pivot['baseline'] * 100).round(1)\n",
    "\n",
    "fig = px.bar(\n",
    "    pivot, x='metric', y='resilience_pct', color='facility',\n",
    "    barmode='group', color_discrete_map=COLORS,\n",
    ")\n",
    "fig = apply_portfolio_style(fig, 'Facility Resilience: Worst Case vs Baseline (% Change)')\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(height=500)\n",
    "save_figure(fig, '../outputs/facility_resilience')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AI-Powered Scenario Interpretation\n",
    "\n",
    "We send the scenario modeling results to Claude API to generate strategic interpretation.\n",
    "\n",
    "> **Note:** This section requires an `ANTHROPIC_API_KEY` in your `.env` file. If not set, the cells will show a placeholder message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "try:\n    analyst = import_from('../../01_scenario_modeling/src/scenario_analyst.py', 'scenario_analyst')\n    \n    analysis = analyst.analyze_scenario_results(endpoint_df.to_csv(index=False))\n    print('=== SCENARIO ANALYSIS ===')\n    print(analysis)\nexcept Exception as e:\n    print(f'AI analysis unavailable: {e}')\n    print('Set ANTHROPIC_API_KEY in .env to enable AI-powered interpretation.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "try:\n    narrative = analyst.generate_scenario_narrative(endpoint_df.to_csv(index=False))\n    print('=== EXECUTIVE BRIEFING ===')\n    print(narrative)\nexcept Exception as e:\n    print(f'AI narrative unavailable: {e}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Outputs\n",
    "\n",
    "Export all scenario modeling artifacts for use in other deliverables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path('../outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "flat_df.to_csv(output_dir / 'scenario_projections.csv', index=False)\n",
    "endpoint_df.to_csv(output_dir / 'scenario_endpoint_summary.csv', index=False)\n",
    "processed['summary'].to_csv(output_dir / 'summary_stats.csv', index=False)\n",
    "processed['anomalies'].to_csv(output_dir / 'anomalies.csv', index=False)\n",
    "processed['correlations'].to_csv(output_dir / 'correlations.csv', index=False)\n",
    "\n",
    "print('All outputs saved to 01_scenario_modeling/outputs/')\n",
    "for f in sorted(output_dir.iterdir()):\n",
    "    print(f'  {f.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This deliverable demonstrates:\n",
    "\n",
    "| Capability | Implementation |\n",
    "|---|---|\n",
    "| Data Engineering | Synthetic data generator with realistic patterns, trends, and anomalies |\n",
    "| Statistical Analysis | Summary stats, trend detection, z-score anomaly flagging, cross-metric correlations |\n",
    "| Scenario Modeling | Monte Carlo simulation engine with configurable scenarios and uncertainty quantification |\n",
    "| Data Visualization | Interactive Plotly fan charts, uncertainty bars, resilience comparisons |\n",
    "| AI Integration | Claude API for strategic scenario interpretation and executive briefing generation |\n",
    "\n",
    "**Next:** See [02_insight_extraction](../../02_insight_extraction/notebooks/) for the AI insight extraction framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}