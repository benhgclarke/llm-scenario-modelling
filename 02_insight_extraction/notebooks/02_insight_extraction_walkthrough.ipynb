{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 2: AI Insight Extraction Framework\n",
    "\n",
    "**Objective:** Build a structured framework that uses Claude API to automatically extract actionable insights from operational data — trends, anomalies, correlations, facility comparisons, risk assessments, and executive summaries.\n",
    "\n",
    "**What this notebook demonstrates:**\n",
    "1. Loading and processing operational metrics data\n",
    "2. Statistical analysis as input for AI interpretation\n",
    "3. Six types of AI-generated insights using prompt engineering\n",
    "4. Visualizations paired with AI narrative for each analysis type\n",
    "5. Structured output suitable for automated reporting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')  # project root\n",
    "\n",
    "import importlib.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "from shared.data_generation.generate import generate_operational_metrics\n",
    "from shared.utils.processing import run_full_processing\n",
    "from shared.utils.plotting import apply_portfolio_style, save_figure, COLORS\n",
    "\n",
    "# Helper to import from digit-prefixed folders\n",
    "def import_from(module_path, module_name):\n",
    "    spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(mod)\n",
    "    return mod\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (generate if needed)\n",
    "data_path = Path('../data/operational_metrics.csv')\n",
    "if data_path.exists():\n",
    "    raw_df = pd.read_csv(data_path, parse_dates=['date'])\n",
    "    print(f'Loaded existing data: {len(raw_df)} rows')\n",
    "else:\n",
    "    raw_df = generate_operational_metrics()\n",
    "    from shared.data_generation.generate import save_data\n",
    "    save_data(raw_df, '../data')\n",
    "    print(f'Generated new data: {len(raw_df)} rows')\n",
    "\n",
    "# Run processing pipeline\n",
    "processed = run_full_processing(raw_df)\n",
    "for name, df in processed.items():\n",
    "    print(f'  {name}: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trend Analysis\n",
    "\n",
    "We compute month-over-month changes and visualize trends, then ask Claude to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = processed['trends']\n",
    "\n",
    "# Average MoM change by metric and facility\n",
    "avg_mom = trends.groupby(['facility', 'metric'])['mom_change'].mean().reset_index()\n",
    "avg_mom.columns = ['facility', 'metric', 'avg_mom_change_pct']\n",
    "avg_mom = avg_mom.sort_values('avg_mom_change_pct')\n",
    "\n",
    "fig = px.bar(\n",
    "    avg_mom, x='metric', y='avg_mom_change_pct', color='facility',\n",
    "    barmode='group', color_discrete_map=COLORS,\n",
    ")\n",
    "fig = apply_portfolio_style(fig, 'Average Month-over-Month Change by Metric')\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(height=500)\n",
    "fig.add_hline(y=0, line_dash='dash', line_color='gray')\n",
    "save_figure(fig, '../outputs/trend_analysis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend volatility: how consistent are the MoM changes?\n",
    "vol = trends.groupby(['facility', 'metric'])['mom_change'].std().reset_index()\n",
    "vol.columns = ['facility', 'metric', 'mom_volatility']\n",
    "\n",
    "fig = px.bar(\n",
    "    vol.sort_values('mom_volatility', ascending=False),\n",
    "    x='metric', y='mom_volatility', color='facility',\n",
    "    barmode='group', color_discrete_map=COLORS,\n",
    ")\n",
    "fig = apply_portfolio_style(fig, 'Trend Volatility (MoM Change Std Dev)')\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(height=500)\n",
    "save_figure(fig, '../outputs/trend_volatility')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Trend Analysis\n",
    "try:\n",
    "    extractor = import_from('../../02_insight_extraction/src/extractor.py', 'extractor')\n",
    "    trend_insight = extractor.analyze_trends(trends.tail(200).to_csv(index=False))\n",
    "    print('=== AI TREND ANALYSIS ===')\n",
    "    print(trend_insight)\n",
    "except Exception as e:\n",
    "    print(f'AI analysis unavailable: {e}')\n",
    "    print('Set ANTHROPIC_API_KEY in .env to enable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anomaly Detection & Assessment\n",
    "\n",
    "Z-score based anomaly detection flags unusual data points. Claude assesses their business significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = processed['anomalies']\n",
    "print(f'Total anomalies detected: {len(anomalies)}')\n",
    "print(f'\\nBy facility:')\n",
    "print(anomalies['facility'].value_counts())\n",
    "print(f'\\nBy metric:')\n",
    "print(anomalies['metric'].value_counts())\n",
    "anomalies.sort_values('z_score', key=abs, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly timeline\n",
    "if len(anomalies) > 0:\n",
    "    fig = px.scatter(\n",
    "        anomalies, x='date', y='z_score', color='facility',\n",
    "        symbol='metric', size=anomalies['z_score'].abs(),\n",
    "        hover_data=['metric', 'value', 'unit'],\n",
    "        color_discrete_map=COLORS,\n",
    "    )\n",
    "    fig.add_hline(y=2, line_dash='dash', line_color='orange', annotation_text='Warning')\n",
    "    fig.add_hline(y=-2, line_dash='dash', line_color='orange')\n",
    "    fig.add_hline(y=3, line_dash='dash', line_color='red', annotation_text='Critical')\n",
    "    fig.add_hline(y=-3, line_dash='dash', line_color='red')\n",
    "    fig = apply_portfolio_style(fig, 'Anomaly Timeline with Severity Bands')\n",
    "    fig.update_layout(height=500)\n",
    "    save_figure(fig, '../outputs/anomaly_timeline')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Anomaly Assessment\n",
    "try:\n",
    "    anomaly_insight = extractor.analyze_anomalies(anomalies.to_csv(index=False))\n",
    "    print('=== AI ANOMALY ASSESSMENT ===')\n",
    "    print(anomaly_insight)\n",
    "except Exception as e:\n",
    "    print(f'AI analysis unavailable: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Metric Correlations\n",
    "\n",
    "Understand which metrics move together — revealing causal relationships and operational levers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = processed['correlations']\n",
    "\n",
    "# Heatmap for each facility\n",
    "for facility in raw_df['facility'].unique():\n",
    "    fac_corr = corr[corr['facility'] == facility]\n",
    "    metrics = sorted(set(fac_corr['metric_1']) | set(fac_corr['metric_2']))\n",
    "    matrix = pd.DataFrame(1.0, index=metrics, columns=metrics)\n",
    "    for _, row in fac_corr.iterrows():\n",
    "        matrix.loc[row['metric_1'], row['metric_2']] = row['correlation']\n",
    "        matrix.loc[row['metric_2'], row['metric_1']] = row['correlation']\n",
    "\n",
    "    fig = px.imshow(\n",
    "        matrix, text_auto='.2f', color_continuous_scale='RdBu_r',\n",
    "        zmin=-1, zmax=1,\n",
    "    )\n",
    "    fig = apply_portfolio_style(fig, f'Metric Correlation Matrix — {facility}')\n",
    "    fig.update_layout(height=500, width=600)\n",
    "    save_figure(fig, f'../outputs/correlation_{facility.lower().replace(\" \", \"_\")}')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strongest correlations across all facilities\n",
    "strong = corr[corr['correlation'].abs() > 0.5].sort_values('correlation', key=abs, ascending=False)\n",
    "print(f'Strong correlations (|r| > 0.5): {len(strong)}')\n",
    "strong.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Correlation Analysis\n",
    "try:\n",
    "    if len(strong) > 0:\n",
    "        corr_insight = extractor.analyze_correlations(strong.to_csv(index=False))\n",
    "        print('=== AI CORRELATION ANALYSIS ===')\n",
    "        print(corr_insight)\n",
    "    else:\n",
    "        print('No strong correlations to analyze.')\n",
    "except Exception as e:\n",
    "    print(f'AI analysis unavailable: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Facility Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = processed['summary']\n",
    "\n",
    "# Radar chart comparing facilities\n",
    "# Normalize metrics to 0-100 scale for comparison\n",
    "radar_data = summary.pivot_table(index='metric', columns='facility', values='mean')\n",
    "radar_norm = radar_data.apply(lambda x: (x - x.min()) / (x.max() - x.min()) * 100, axis=1)\n",
    "\n",
    "fig = go.Figure()\n",
    "for facility in radar_norm.columns:\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=radar_norm[facility].tolist() + [radar_norm[facility].iloc[0]],\n",
    "        theta=radar_norm.index.tolist() + [radar_norm.index[0]],\n",
    "        fill='toself', name=facility, opacity=0.6,\n",
    "        line=dict(color=COLORS.get(facility)),\n",
    "    ))\n",
    "\n",
    "fig = apply_portfolio_style(fig, 'Facility Performance Radar (Normalized)')\n",
    "fig.update_layout(height=550, polar=dict(radialaxis=dict(visible=True, range=[0, 100])))\n",
    "save_figure(fig, '../outputs/facility_radar')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Facility Comparison\n",
    "try:\n",
    "    comparison_insight = extractor.compare_facilities(summary.to_csv(index=False))\n",
    "    print('=== AI FACILITY COMPARISON ===')\n",
    "    print(comparison_insight)\n",
    "except Exception as e:\n",
    "    print(f'AI analysis unavailable: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Risk Assessment & Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Risk Assessment\n",
    "try:\n",
    "    risk_insight = extractor.assess_risks(\n",
    "        anomalies.to_csv(index=False),\n",
    "        processed['trends'].tail(100).to_csv(index=False),\n",
    "    )\n",
    "    print('=== AI RISK ASSESSMENT ===')\n",
    "    print(risk_insight)\n",
    "except Exception as e:\n",
    "    print(f'AI analysis unavailable: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Executive Summary\n",
    "try:\n",
    "    exec_summary = extractor.generate_executive_summary(\n",
    "        summary.to_csv(index=False),\n",
    "        processed['trends'].tail(200).to_csv(index=False),\n",
    "        anomalies.to_csv(index=False),\n",
    "    )\n",
    "    print('=== AI EXECUTIVE SUMMARY ===')\n",
    "    print(exec_summary)\n",
    "except Exception as e:\n",
    "    print(f'AI analysis unavailable: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('../outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "processed['summary'].to_csv(output_dir / 'summary_stats.csv', index=False)\n",
    "processed['trends'].to_csv(output_dir / 'trends.csv', index=False)\n",
    "processed['anomalies'].to_csv(output_dir / 'anomalies.csv', index=False)\n",
    "processed['correlations'].to_csv(output_dir / 'correlations.csv', index=False)\n",
    "strong.to_csv(output_dir / 'strong_correlations.csv', index=False)\n",
    "\n",
    "print('All outputs saved to 02_insight_extraction/outputs/')\n",
    "for f in sorted(output_dir.iterdir()):\n",
    "    print(f'  {f.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Insight Type | Statistical Input | AI Analysis |\n",
    "|---|---|---|\n",
    "| Trend Analysis | MoM change computation, volatility metrics | Pattern identification, action recommendations |\n",
    "| Anomaly Detection | Z-score flagging (threshold = 2.0) | Business impact assessment, investigation priorities |\n",
    "| Correlation Analysis | Pearson cross-metric correlations | Causal vs. spurious identification, operational levers |\n",
    "| Facility Comparison | Normalized performance metrics | Rankings, best practice transfer recommendations |\n",
    "| Risk Assessment | Combined anomaly + trend data | Risk ranking, early warning indicators, mitigation strategies |\n",
    "| Executive Summary | Full dataset summary | Health assessment, wins/concerns, 30-day and quarterly actions |\n",
    "\n",
    "**Next:** See [03_strategic_dashboard](../../03_strategic_dashboard/notebooks/) for the interactive dashboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
